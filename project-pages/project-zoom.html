<!DOCTYPE HTML>
<!--
	Future Imperfect by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>CZ-ZOOM</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main2.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="single is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="../index.html#research">Back to research</a></h1>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<article class="post">
								<header>
									<div class="title">
										<h2><a href="#">Zoom to Learn, Learn to Zoom</a></h2>
									</div>
									<div class="meta">
										<!-- <time class="published" datetime="2018-06-23">In CVPR 2019</time> -->
										<a href="../index.html" class="author"><span class="name">Cecilia Zhang &#9749</span></a>
									</div>
								</header>
								<p>
									<font face="Raleway" size="4"> Cecilia Zhang, Qifeng Chen, Ren Ng, Vladlen Koltun </font>
								</p>
								<a href="" target="_blank" class="image fit"><img src="https://dl.dropboxusercontent.com/s/7t4zh9xh0comq90/zoom.jpg?dl=0" alt="cvpr 2019 paper figure"></a>
								<o><font face="Raleway" color="#bbbbbb">Abstract</font></o>
								<p>
									This paper shows that when applying machine learning to digital zoom for photography, it is beneficial to use real, RAW sensor data for training. Existing learning-based super-resolution methods do not use real sensor data, instead operating on RGB images. In practice, these approaches result in loss of detail and accuracy in their digitally zoomed output when zooming in on distant image regions. We also show that synthesizing sensor data by resampling high-resolution RGB images is an oversimplified approximation of real sensor data and noise, resulting in worse image quality. The key barrier to using real sensor data for training is that ground truth high-resolution imagery is missing. We show how to obtain the ground-truth data with optically zoomed images and contribute a dataset, SR-RAW, for real-world computational zoom. We use SR-RAW to train a deep network with a novel contextual bilateral loss (CoBi) that delivers critical robustness to mild misalignment in input-output image pairs. The trained network achieves state-of-the-art performance in 4X and 8X computational zoom.
								</p>
								<o><font face="Raleway" color="#bbbbbb">Material</font></o>
								<p>
									<a class="fa fa-file-text-o";background-repeat: no-repeat;background-position: 5px center;" href="http://vladlen.info/papers/zoom.pdf"> Paper</a></li>
								</p>

							</article>
					</div>

				<!-- Footer -->
					<section id="footer">
						<p class="copyright">&copy; Untitled. Design: <a href="http://html5up.net">HTML5 UP</a>. Images: <a href="http://unsplash.com">Unsplash</a>.</p>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>